{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Shape data\n",
    "\n",
    "# Data\n",
    "There are 3 directories with images\n",
    "- train\n",
    "- val\n",
    "- test\n",
    "Each user has all their images in 1 of 3 directories\n",
    "---\n",
    "## Processing\n",
    "For each the Train, Validation and Test set:\n",
    "- Load the image files\n",
    "- Normalize image:\n",
    "  - All gray pixel are represented as a value between 0 and 1.\n",
    "  - Black on white images are transforme to white on black.\n",
    "- Prepare the labels based on the directory name  \n",
    "- Load Train, Validation and test data into pickles for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "from six.moves import cPickle as pickle\n",
    "import ntpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.3\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASEDIR = \"..\"\n",
    "\n",
    "DATA_DIR        = os.path.join(BASEDIR, \"data\")\n",
    "TRAIN_DATADIR   = os.path.join(DATA_DIR, \"train\")\n",
    "VAL_DATADIR     = os.path.join(DATA_DIR, \"val\")\n",
    "TEST_DATADIR    = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "PICKLE_DIR     = os.path.join(BASEDIR, \"pickles\")\n",
    "TRAIN_DATAFILE = os.path.join(PICKLE_DIR, 'train.pickle')\n",
    "VAL_DATAFILE   = os.path.join(PICKLE_DIR, 'val.pickle')\n",
    "TEST_DATAFILE  = os.path.join(PICKLE_DIR, 'test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for getting array of directory paths and array of file paths\n",
    "def get_dir_paths(root):\n",
    "    return [os.path.join(root, n) for n in sorted(os.listdir(root)) if os.path.isdir(os.path.join(root, n))]\n",
    "\n",
    "\n",
    "def get_file_paths(root):\n",
    "    return [os.path.join(root, n) for n in sorted(os.listdir(root)) if os.path.isfile(os.path.join(root, n))]\n",
    "\n",
    "\n",
    "def path_leaf(path):  # From: https://stackoverflow.com/questions/8384737/extract-file-name-from-path-no-matter-what-the-os-path-format\n",
    "    head, tail = ntpath.split(path)\n",
    "    return tail or ntpath.basename(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get directory and file paths of training, validation and test sets\n",
    "train_data_paths = get_dir_paths(TRAIN_DATADIR)\n",
    "val_data_paths   = get_dir_paths(VAL_DATADIR)\n",
    "test_data_paths  = get_dir_paths(TEST_DATADIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image properties\n",
    "image_size  = 70 # Pixel width and height\n",
    "pixel_depth = 255.0  # Number of levels per pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_for_shape(shape_dir):\n",
    "    shape = os.path.basename(shape_dir)\n",
    "    if shape == \"other\":\n",
    "        return 0\n",
    "    elif shape == \"ellipse\":\n",
    "        return 1\n",
    "    elif shape == \"rectangle\":\n",
    "        return 2\n",
    "    elif shape == \"triangle\":\n",
    "        return 3\n",
    "    else:\n",
    "        raise Exception('Unknown shape: %s' % shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image by pixel depth by making it white on black instead of black on white\n",
    "def normalize_image(image_file, pixel_depth):\n",
    "    try:\n",
    "        array = imageio.imread(image_file)\n",
    "    except ValueError:\n",
    "        raise\n",
    "\n",
    "    return 1.0 - (array.astype(float))/pixel_depth  # (1 - x) will make it white on black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for saving an object to a pickle file\n",
    "def save_to_pickle(pickle_file, object, force=False):\n",
    "    if os.path.exists(pickle_file) and not force:\n",
    "        print('%s already present, skipping pickling' % pickle_file)\n",
    "    else:\n",
    "        try:\n",
    "            f = open(pickle_file, 'wb')\n",
    "            pickle.dump(object, f, pickle.HIGHEST_PROTOCOL)\n",
    "            f.close()\n",
    "        except Exception as e:\n",
    "            print('Unable to save object to', pickle_file, ':', e)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_for_shape(root, pixel_depth, user_images,\n",
    "                          user_images_label, label, verbose=False, min_nimages=1):\n",
    "\n",
    "    if verbose:\n",
    "        print(\"root for load_images_for_shapes: \", root)\n",
    "\n",
    "    image_files = get_file_paths(root)\n",
    "    image_index = 0\n",
    "\n",
    "    for image_file in image_files:\n",
    "        try:\n",
    "            if path_leaf(image_file).startswith('.'):  # skip files like .DSStore\n",
    "                continue\n",
    "\n",
    "            image_data_all_channels = normalize_image(image_file, pixel_depth)\n",
    "            # print(image_data_all_channels.shape)\n",
    "            image_data = image_data_all_channels[:, :, 0]\n",
    "            # print(image_data.shape)\n",
    "\n",
    "            user_images.append(image_data)\n",
    "            user_images_label.append(label)\n",
    "            image_index += 1\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            print('Skipping because of not being able to read: ', image_file)\n",
    "\n",
    "    if image_index < min_nimages:\n",
    "        raise Exception('Fewer images than expected: %d < %d' % (image_index, min_nimages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_for_user(root, pixel_depth, user_images, user_images_label, verbose=False):\n",
    "    images_dir = os.path.join(root, \"images\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"root for load_images_for_shapes: \", images_dir)\n",
    "\n",
    "    shape_dirs = get_dir_paths(images_dir)\n",
    "    for dir in shape_dirs:\n",
    "        label = get_label_for_shape(dir)\n",
    "        if label >= 0:\n",
    "            load_images_for_shape(dir, pixel_depth, user_images, user_images_label, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape:  (21393, 70, 70)\n",
      "train_labels shape:  (21393,)\n",
      "train label dist.:  {0: 5316, 1: 5025, 2: 5740, 3: 5312}\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "train_user_images = []\n",
    "train_user_images_label = []\n",
    "\n",
    "for userDir in train_data_paths:\n",
    "    load_images_for_user(userDir, pixel_depth, train_user_images, train_user_images_label)\n",
    "\n",
    "train_data = np.array(train_user_images)\n",
    "train_labels = np.array(train_user_images_label)\n",
    "\n",
    "print('train_data shape: ', train_data.shape)\n",
    "print('train_labels shape: ', train_labels.shape)\n",
    "\n",
    "unique, counts = np.unique(train_labels, return_counts=True)\n",
    "print(\"train label dist.: \", dict(zip(unique, counts)))\n",
    "\n",
    "# Save train data to single pickle file\n",
    "save_to_pickle(\n",
    "    TRAIN_DATAFILE,\n",
    "    {\n",
    "        'train_data': train_data,\n",
    "        'train_labels': train_labels\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data\n",
    "del train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_data shape:  (3983, 70, 70)\n",
      "val_labels shape:  (3983,)\n",
      "val label dist.:  {0: 1130, 1: 1069, 2: 860, 3: 924}\n"
     ]
    }
   ],
   "source": [
    "# Validation data\n",
    "val_user_images = []\n",
    "val_user_images_label = []\n",
    "\n",
    "for userDir in val_data_paths:\n",
    "    load_images_for_user(userDir, pixel_depth, val_user_images, val_user_images_label)\n",
    "\n",
    "val_data = np.array(val_user_images)\n",
    "val_labels = np.array(val_user_images_label)\n",
    "\n",
    "print('val_data shape: ', val_data.shape)\n",
    "print('val_labels shape: ', val_labels.shape)\n",
    "unique, counts = np.unique(val_labels, return_counts=True)\n",
    "print(\"val label dist.: \", dict(zip(unique, counts)))\n",
    "\n",
    "# Save validation data to single pickle file\n",
    "save_to_pickle(\n",
    "    VAL_DATAFILE,\n",
    "    {\n",
    "        'val_data': val_data,\n",
    "        'val_labels': val_labels\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del val_data\n",
    "del val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data shape:  (1923, 70, 70)\n",
      "test_labels shape:  (1923,)\n",
      "test label dist.:  {0: 841, 1: 360, 2: 359, 3: 363}\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "test_user_images = []\n",
    "test_user_images_label = []\n",
    "\n",
    "for userDir in test_data_paths:\n",
    "    load_images_for_user(userDir, pixel_depth, test_user_images, test_user_images_label)\n",
    "\n",
    "test_data   = np.array(test_user_images)\n",
    "test_labels = np.array(test_user_images_label)\n",
    "\n",
    "print('test_data shape: ', test_data.shape)\n",
    "print('test_labels shape: ', test_labels.shape)\n",
    "unique, counts = np.unique(test_labels, return_counts=True)\n",
    "print(\"test label dist.: \", dict(zip(unique, counts)))\n",
    "\n",
    "# Save Test data to single pickle file\n",
    "save_to_pickle(\n",
    "    TEST_DATAFILE,\n",
    "    {\n",
    "        'test_data': test_data,\n",
    "        'test_labels': test_labels\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
